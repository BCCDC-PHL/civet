import csv
from Bio import SeqIO
import os
import collections

if config["fasta"] != "":
    rule all:
        input:
            os.path.join(config["outdir"],"combined_metadata.csv"),
            os.path.join(config["outdir"],"lineage_trees","lineage_tree_summary.txt")
else:
    rule all:
        input:
            os.path.join(config["outdir"],"query_in_cog.csv"),
            os.path.join(config["outdir"],"lineage_trees","lineage_tree_summary.txt")

rule check_cog_db:
    input:
        query = config["query"],
        cog_seqs = config["cog_seqs"],
        metadata = config["cog_metadata"]
    output:
        cog = os.path.join(config["outdir"],"query_in_cog.csv"),
        cog_seqs = os.path.join(config["outdir"],"query_in_cog.fasta"),
        not_cog = os.path.join(config["outdir"],"not_in_cog.csv")
    run:
        query_names = []
        in_cog_metadata = []
        in_cog_names = set()
        with open(input.query,newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                query_names.append(row["name"])

        with open(input.metadata,newline="") as f:
            reader = csv.DictReader(f)
            header_names = reader.fieldnames
            for row in reader:
                for seq in query_names:
                    if seq in row["sequence_name"]:
                        print(seq)
                        row["query"]=row["sequence_name"]
                        row["closest"]=row["sequence_name"]
                        in_cog_metadata.append(row)
                        in_cog_names.add(row["sequence_name"])

            print(f"Number of seqs found in metadata: {len(in_cog_metadata)}")
            with open(output.cog, "w") as fw:
                header_names.append("query")
                header_names.append("closest")
                writer = csv.DictWriter(fw, fieldnames=header_names)
                writer.writeheader()
                writer.writerows(in_cog_metadata)

        fw = open(output.cog_seqs, "w")
        for record in SeqIO.parse(input.cog_seqs, "fasta"):
            for name in query_names:
                if name in record.id:
                    fw.write(f">{record.id}\n{record.seq}\n")
        
        with open(output.not_cog, "w") as fw:
            print("The following sequences were not found in the cog database:\n")
            for query in query_names:
                in_cog = False
                for name in in_cog_names:
                    if query in name:
                        in_cog = True
                if not in_cog:
                    fw.write(query + '\n')
                    print(f"{query}")

rule non_cog_match_fasta:
    input:
        fasta = config["post_qc_query"],
        not_cog = rules.check_cog_db.output.not_cog
    output:
        fasta = os.path.join(config["outdir"],"not_in_cog.fasta")
    run:
        not_cog = []
        with open(input.not_cog, "r") as f:
            for l in f:
                l = l.rstrip("\n")
                not_cog.append(l)
        in_fasta = []
        with open(output.fasta, "w") as fw:
            for record in SeqIO.parse(input.fasta, "fasta"):
                if record.id in not_cog:
                    fw.write(f">{record.id}\n{record.seq}\n")
                    in_fasta.append(record.id)
                else:
                    in_fasta.append(record.id)
        print("The following sequences queried not in COG \nand not in fasta file so cannot be analysed\n")
        for record in not_cog:
            if record not in in_fasta: 
                print(record)
                
rule non_cog_minimap2_to_reference:
    input:
        fasta = rules.non_cog_match_fasta.output.fasta,
        reference = config["reference_fasta"]
    output:
        sam = os.path.join(config["outdir"],"post_qc_query.reference_mapped.sam")
    shell:
        """
        minimap2 -a -x asm5 {input.reference} {input.fasta} > {output.sam}
        """

rule non_cog_remove_insertions_and_trim_and_pad:
    input:
        sam = rules.non_cog_minimap2_to_reference.output.sam,
        reference = config["reference_fasta"]
    params:
        trim_start = config["trim_start"],
        trim_end = config["trim_end"],
        insertions = os.path.join(config["outdir"],"post_qc_query.insertions.txt")
    output:
        fasta = os.path.join(config["outdir"],"post_qc_query.alignment.trimmed.fasta")
    shell:
        """
        datafunk sam_2_fasta \
          -s {input.sam} \
          -r {input.reference} \
          -o {output.fasta} \
          -t [{params.trim_start}:{params.trim_end}] \
          --pad \
          --log-inserts &
        mv insertions.txt {params.insertions}
        """

rule minimap2_against_cog:
    input:
        query_seqs = config["post_qc_query"],
        cog_seqs = config["cog_seqs"]
    output:
        paf = os.path.join(config["outdir"],"post_qc_query.cog_mapped.paf")
    shell:
        """
        minimap2 -x asm5 --secondary=no --paf-no-hit {input.cog_seqs} {input.query_seqs} > {output.paf}
        """

rule parse_paf:
    input:
        paf = rules.minimap2_against_cog.output.paf,
        metadata = config["cog_metadata"],
        fasta = config["cog_seqs"]
    output:
        fasta = os.path.join(config["outdir"],"closest_cog.fasta"),
        csv = os.path.join(config["outdir"],"closest_cog.csv")
    shell:
        """
        parse_paf.py \
        --paf {input.paf:q} \
        --metadata {input.metadata:q} \
        --seqs {input.fasta} \
        --csv-out {output.csv:q} \
        --seqs-out {output.fasta:q}
        """


rule combine_metadata:
    input:
        closest_cog = rules.parse_paf.output.csv,
        in_cog = rules.check_cog_db.output.cog
    output:
        combined_csv = os.path.join(config["outdir"],"combined_metadata.csv")
    run:
        with open(output.combined_csv,"w") as fw:
            with open(input.in_cog, "r") as f:
                for l in f:
                    l = l.rstrip("\n")
                    fw.write(l + '\n')
            with open(input.closest_cog, "r") as f:
                for l in f:
                    l = l.rstrip("\n")
                    if "sequence_name" in l:
                        pass
                    else:
                        fw.write(l + '\n')

if config["remote"]==True:
    rule get_lineage_trees:
        input:
            combined_csv = os.path.join(config["outdir"],"combined_metadata.csv")
        params:
            outdir = os.path.join(config["outdir"],"lineage_trees"),
            uun = config["username"]
        output:
            lineage_trees = os.path.join(config["outdir"],"lineage_trees","lineage_tree_summary.txt")
        run:
            lineages = set()
            with open(input.combined_csv, newline="") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    lineages.add(row["uk_lineage"])
            fw = open(output.lineage_trees, "w")
            for lineage in lineages:
                shell(f"""
                scp {params.uun}@bham.covid19.climb.ac.uk:\
/cephfs/covid/bham/raccoon-dog/2020-05-29/publish\
/phylogenetics/trees/uk_lineages/{lineage}.tree"""
                )
                fw.write(lineage+ '\n')
            fw.close()
else:
    rule get_lineage_trees:
        input:
            combined_csv = os.path.join(config["outdir"],"combined_metadata.csv")
        params:
            outdir = os.path.join(config["outdir"],"lineage_trees"),
            uun = config["username"],
            lineage_dir = config["lineage_dir"]
        output:
            lineage_trees = os.path.join(config["outdir"],"lineage_trees","lineage_tree_summary.txt")
        run:
            lineages = set()
            with open(input.combined_csv, newline="") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    lineages.add(row["uk_lineage"])
            fw = open(output.lineage_trees, "w")
            for lineage in lineages:
                shell(f"""
                scp /cephfs/covid/bham/raccoon-dog/2020-05-29/publish\
/phylogenetics/trees/uk_lineages/{lineage}.tree"""
                )
                fw.write(lineage + '\n')
            fw.close()


