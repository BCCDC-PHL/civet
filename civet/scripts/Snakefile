import csv
from Bio import SeqIO
import os
import collections

if config["fasta"] != "":
    rule all:
        input:
            os.path.join(config["outdir"],"seqs_of_interest.aln.fasta.treefile"),
            os.path.join(config["outdir"],"lineage_report.md"),
            os.path.join(config["outdir"],"pangolin_seqs_of_interest.csv"),
            os.path.join(config["outdir"],"non_cog.fasta")
else:
    rule all:
        input:
            os.path.join(config["outdir"],"seqs_of_interest.aln.fasta.treefile"),
            os.path.join(config["outdir"],"lineage_report.md"),
            os.path.join(config["outdir"],"pangolin_seqs_of_interest.csv")

rule check_cog_db:
    input:
        query = config["query"],
        cog_seqs = config["cog_seqs"],
        metadata = config["cog_metadata"]
    output:
        cog = os.path.join(config["outdir"],"query_in_cog.csv"),
        cog_seqs = os.path.join(config["outdir"],"query_in_cog.fasta"),
        not_cog = os.path.join(config["outdir"],"not_in_cog.csv")
    run:
        query_names = []
        in_cog_metadata = []
        in_cog_names = set()
        with open(input.query,newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                query_names.append(row["name"])

        with open(input.metadata,newline="") as f:
            reader = csv.DictReader(f)
            header_names = reader.fieldnames
            for row in reader:
                for seq in query_names:
                    if seq in row["sequence_name"]:
                        in_cog_metadata.append(row)
                        in_cog_names.add(row["sequence_name"])

            print(f"Number of seqs found in metadata: {len(in_cog_metadata)}")
            with open(output.cog, "w") as fw:
                writer = csv.DictWriter(fw, fieldnames=header_names)
                writer.writeheader()
                writer.writerows(in_cog_metadata)

        fw = open(output.cog_seqs, "w")
        for record in SeqIO.parse(input.cog_seqs, "fasta"):
            if record.id in query_names:
                fw.write(f">{record.id}\n{record.seq}\n")

        with open(output.not_cog, "w") as fw:
            for query in query_seqs:
                if not query in in_cog_names:
                    fw.write(query + '\n')

rule non_cog_minimap2_to_reference:
    input:
        fasta = config["post_qc_query"],
        reference = config["reference_fasta"]
    output:
        sam = os.path.join(config["output_path"],"post_qc_query.mapped.sam")
    shell:
        """
        minimap2 -a -x asm5 {input.reference} {input.fasta} > {output.sam}
        """

rule non_cog_remove_insertions_and_trim_and_pad:
    input:
        sam = rules.non_cog_minimap2_to_reference.output.sam,
        reference = config["reference_fasta"]
    params:
        trim_start = config["trim_start"],
        trim_end = config["trim_end"],
        insertions = os.path.join(config["output_path"],"post_qc_query.insertions.txt")
    output:
        fasta = os.path.join(config["output_path"],"post_qc_query.alignment.trimmed.fasta")
    shell:
        """
        datafunk sam_2_fasta \
          -s {input.sam} \
          -r {input.reference} \
          -o {output.fasta} \
          -t [{params.trim_start}:{params.trim_end}] \
          --pad \
          --log-inserts &> {log}
        mv insertions.txt {params.insertions}
        """

rule pangolin_sequences:
    input:
        rules.grab_seqs.output.fasta
    threads: workflow.cores
    params:
        cores = workflow.cores
    output:
        report = config["outdir"] + "/pangolin_seqs_of_interest.csv"
    shell:
        "pangolin {input[0]:q} -t {params.cores} --outfile {output.report:q}"

rule mafft_sequences:
    input:
        rules.grab_seqs.output.fasta
    threads: workflow.cores
    params:
        cores = workflow.cores
    output:
        fasta = config["outdir"] + "/seqs_of_interest.aln.fasta"
    shell:
        "mafft --thread {params.cores} {input[0]:q} > {output[0]:q}"

rule iqtree_representative_sequences:
    input:
        rules.mafft_sequences.output.fasta
    threads: workflow.cores
    params:
        cores = workflow.cores
    output:
        config["outdir"] + "/seqs_of_interest.aln.fasta.treefile"
    shell:
        "iqtree -s {input[0]:q} -nt AUTO -bb 10000 -m HKY -redo -au -alrt 1000"

rule interpret_cog_metadata:
    input:
        pangolin = rules.pangolin_sequences.output.report,
        metadata = config["outdir"] +"/in_cog_metadata.csv"
    output:
        config["outdir"] +"/lineage_report.md"
    run:
        with open(output[0],"w") as fw:
            fw.write("## Cluster investigation report\n\n")
            fw.write("""This report summarises the information provided by whole genome sequencing of SARS-COV-2 as part of COG-UK. \
The information presented in this report is intended to provide an additional level of information to aid infection control efforts. \
The information we provide is not in any way able to infer direct transmission between two samples. \
Even identical sequences may be unrelated as SARS-COV2 is relatively slow evolving for an RNA virus.\n\n\n""")
            fw.write("""If sequences have different lineage designations, we can rule out transmission. \
If sequences have different phylotypes it's very unlikely that they are direct transmissions. \
If sequences share the same lineage and the same phylotype, it does not imply transmission \
it just means we cannot immediately rule it out.\n""")
            fw.write("## pangolin lineage assignments\n\n")

            fw.write("Confidence values:\nSHalrt= likelihood, UFbootstrap= approximate bootrap for phylogenetic tree.\n")
            with open(input.pangolin, "r") as f:
                for l in f:
                    if l.startswith("taxon"):
                        fw.write("| taxon | lineage | SHalrt | UFbootstrap | lineages_version | status | note |\n|:-----|:-----:|:-----:|:-----:|:-----:|:-----:|:-----|\n")
                    else:
                        l = l.rstrip("\n")
                        write_str = " | ".join(l.split(","))
                        fw.write("| "+write_str + " |\n")
            fw.write("\n********\n")

            fw.write("### Sequences analysed as part of COG\n")
            
            phylotype_dict = collections.defaultdict(list)
            lineage_dict = collections.defaultdict(list)
            with open(input.metadata,newline="") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    fw.write(row["sequence_name"] + '\n')
                    # phylotype_dict[row["phylotype"]].append(row["name"])
                    lineage_dict[row["lineage"]].append(row["sequence_name"])
            fw.write("\n********\n")
            fw.write("| Lineage | Queries |\n|:-----:|:-----|\n")
            for lineage in lineage_dict:
                fw.write(f"| {lineage} | ")
                for sequence in lineage_dict[lineage]:
                    fw.write(f" {sequence}<br>")
            fw.write(" |\n\n")
            
            fw.close()


